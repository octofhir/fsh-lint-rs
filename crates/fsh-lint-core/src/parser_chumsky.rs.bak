use chumsky::extra;
use chumsky::input::Stream;
use chumsky::prelude::*;
use chumsky::recovery::skip_then_retry_until;

use crate::ast::{
    Alias, BindingStrength, Cardinality, CardinalityMax, CaretValueRule, Code, CodeCaretValueRule,
    CodeInsertRule, Concept, ContainsItem, ContainsRule, Extension, FixedValueRule, Flag,
    FlagRule, FSHDocument, InsertRule, Instance, InstanceRule, Invariant, LRRule, Logical,
    Mapping, ObeysRule, OnlyRule, PathRule, Profile, Resource, SDRule, Spanned, VSComponent,
    VSComponentType, VSConceptComponent, VSFilter, VSFilterComponent, VSRule, Value, ValueSet,
    ValueSetRule, CodeSystem, CSRule, AddElementRule,
};
use crate::lexer::{LexSpan, Token};

type ParserInput<'tokens, 'src> = &'tokens [(Token, LexSpan)];

type ParserExtra<'tokens> = extra::Err<Rich<'tokens, Token>>;

// Chumsky 0.10 doesn't have BoxedParser, we'll just use the concrete impl type

#[derive(Debug, Clone)]
enum Entity {
    Alias(Alias),
    Profile(Profile),
    Extension(Extension),
    ValueSet(ValueSet),
    CodeSystem(CodeSystem),
    Instance(Instance),
    Invariant(Invariant),
    Mapping(Mapping),
    Logical(Logical),
    Resource(Resource),
}

#[derive(Debug, Clone)]
enum ValueSetLine {
    Component(VSComponent),
    Rule(VSRule),
}

fn entity<'tokens>()
-> impl Parser<'tokens, Stream<'tokens, Token, LexSpan>, Entity, ParserExtra<'tokens>> + Clone {
    choice((
        alias_parser().map(Entity::Alias),
        profile_parser().map(Entity::Profile),
        extension_parser().map(Entity::Extension),
        value_set_parser().map(Entity::ValueSet),
        code_system_parser().map(Entity::CodeSystem),
        instance_parser().map(Entity::Instance),
        invariant_parser().map(Entity::Invariant),
        mapping_parser().map(Entity::Mapping),
        logical_parser().map(Entity::Logical),
        resource_parser().map(Entity::Resource),
    ))
    .recover_with(skip_then_retry_until(any().ignored(), end()))
}

pub fn fsh_document_parser<'tokens>(
) -> impl Parser<'tokens, Stream<'tokens, Token, LexSpan>, FSHDocument, ParserExtra<'tokens>> + Clone {
    entity()
        .repeated()
        .collect::<Vec<_>>()
        .map_with(|entities, ext| {
            let span = ext.span();
            let span = to_range(span);
            let mut document = FSHDocument::new(span.clone());

            for entity in entities {
                match entity {
                    Entity::Alias(a) => document.aliases.push(a),
                    Entity::Profile(p) => document.profiles.push(p),
                    Entity::Extension(e) => document.extensions.push(e),
                    Entity::ValueSet(vs) => document.value_sets.push(vs),
                    Entity::CodeSystem(cs) => document.code_systems.push(cs),
                    Entity::Instance(i) => document.instances.push(i),
                    Entity::Invariant(inv) => document.invariants.push(inv),
                    Entity::Mapping(m) => document.mappings.push(m),
                    Entity::Logical(l) => document.logicals.push(l),
                    Entity::Resource(r) => document.resources.push(r),
                }
            }

            document
        })
}

pub fn parse_tokens<'tokens>(
    tokens: &'tokens [(Token, LexSpan)],
    eof: LexSpan,
) -> (Option<FSHDocument>, Vec<Rich<'tokens, Token>>) {
    let parser = fsh_document_parser();
    let stream = Stream::from_iter(eof, tokens.iter().cloned());
    let (doc, errors) = parser.parse(stream).into_output_errors();
    (doc, errors)
}

fn value_set_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ValueSet, ParserExtra<'tokens>> + Clone {
    just(Token::ValueSet)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(metadata().repeated().collect::<Vec<_>>())
        .then(value_set_line().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), lines), span| {
            let span = to_range(span);
            let mut value_set = ValueSet {
                name,
                id: None,
                title: None,
                description: None,
                components: Vec::new(),
                rules: Vec::new(),
                span,
            };

            for meta in metadata {
                match meta {
                    Metadata::Id(id) => value_set.id = Some(id),
                    Metadata::Title(title) => value_set.title = Some(title),
                    Metadata::Description(desc) => value_set.description = Some(desc),
                }
            }

            for line in lines {
                match line {
                    ValueSetLine::Component(component) => value_set.components.push(component),
                    ValueSetLine::Rule(rule) => value_set.rules.push(rule),
                }
            }

            value_set
        })
}

fn value_set_line<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ValueSetLine, ParserExtra<'tokens>> + Clone {
    choice((
        vs_component().map(ValueSetLine::Component),
        vs_rule_parser().map(ValueSetLine::Rule),
    ))
}

fn vs_rule_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, VSRule, ParserExtra<'tokens>> + Clone {
    choice((
        caret_value_rule().map(VSRule::CaretValue),
        code_caret_value_rule().map(VSRule::CodeCaretValue),
        insert_rule().map(VSRule::Insert),
        code_insert_rule().map(VSRule::CodeInsert),
    ))
}

fn caret_value_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, CaretValueRule, ParserExtra<'tokens>> + Clone {
    let path = string_like().map(Some).then_ignore(just(Token::Caret));
    let no_path = just(Token::Caret).to(None::<Spanned<String>>);

    just(Token::Star)
        .ignore_then(path.or(no_path))
        .then(string_like())
        .then_ignore(just(Token::Equal))
        .then(value_literal())
        .map_with_span(|((path, caret_path), value), span| CaretValueRule {
            path,
            caret_path,
            value,
            span: to_range(span),
        })
}

fn code_caret_value_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, CodeCaretValueRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(code_literal().repeated().at_least(1).collect::<Vec<_>>())
        .then_ignore(just(Token::Caret))
        .then(string_like())
        .then_ignore(just(Token::Equal))
        .then(value_literal())
        .map_with_span(|((codes, caret_path), value), span| CodeCaretValueRule {
            codes,
            caret_path,
            value,
            span: to_range(span),
        })
}

fn insert_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, InsertRule, ParserExtra<'tokens>> + Clone {
    let path = string_like().map(Some).then_ignore(just(Token::Insert));
    let no_path = just(Token::Insert).to(None::<Spanned<String>>);

    just(Token::Star)
        .ignore_then(path.or(no_path))
        .then(string_like())
        .map_with_span(|(path, rule_set), span| InsertRule {
            path,
            rule_set,
            span: to_range(span),
        })
}

fn code_insert_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, CodeInsertRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(code_literal().repeated().at_least(1).collect::<Vec<_>>())
        .then_ignore(just(Token::Insert))
        .then(string_like())
        .map_with_span(|(codes, rule_set), span| CodeInsertRule {
            codes,
            rule_set,
            span: to_range(span),
        })
}

#[derive(Debug, Clone)]
enum Metadata {
    Id(Spanned<String>),
    Title(Spanned<String>),
    Description(Spanned<String>),
}

fn metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Metadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Id)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(Metadata::Id),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(Metadata::Title),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(Metadata::Description),
    ))
}

fn vs_component<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, VSComponent, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(
            choice((
                just(Token::Include).to(true),
                just(Token::Exclude).to(false),
            ))
            .or_not(),
        )
        .then(choice((vs_codes_component(), vs_code_component())))
        .map_with_span(|(include, component_type), span| VSComponent {
            include: include.unwrap_or(true),
            component_type,
            span: to_range(span),
        })
}

fn vs_codes_component<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, VSComponentType, ParserExtra<'tokens>> + Clone {
    just(Token::Codes)
        .ignore_then(just(Token::From))
        .ignore_then(vs_component_source())
        .then(vs_filters().or_not())
        .map(|((from_system, from_valueset), filters)| {
            VSComponentType::Filter(VSFilterComponent {
                from_system,
                from_valueset,
                filters: filters.unwrap_or_default(),
            })
        })
}

fn vs_code_component<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, VSComponentType, ParserExtra<'tokens>> + Clone {
    code_literal().map(|code| {
        VSComponentType::Concept(VSConceptComponent {
            code,
            from_system: None,
            from_valueset: Vec::new(),
        })
    })
}

fn vs_component_source<'tokens>() -> impl Parser<
    'tokens,
    ParserInput<'tokens>,
    (Option<Spanned<String>>, Vec<Spanned<String>>),
    ParserExtra<'tokens>,
> + Clone {
    let system = just(Token::System).ignore_then(string_like()).or_not();

    let first_valueset = just(Token::ValueSetRef).ignore_then(string_like()).or_not();

    let additional_valuesets = just(Token::And)
        .ignore_then(just(Token::ValueSetRef).ignore_then(string_like()))
        .repeated()
        .collect::<Vec<_>>();

    system
        .then(first_valueset)
        .then(additional_valuesets)
        .map(|((system, first), mut rest)| {
            if let Some(first_vs) = first {
                rest.insert(0, first_vs);
            }
            (system, rest)
        })
}

fn vs_filters<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Vec<VSFilter>, ParserExtra<'tokens>> + Clone {
    just(Token::Where).ignore_then(
        vs_filter()
            .separated_by(just(Token::And))
            .collect::<Vec<_>>(),
    )
}

fn vs_filter<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, VSFilter, ParserExtra<'tokens>> + Clone {
    string_like()
        .then(string_like())
        .then(value_literal().or_not())
        .map_with_span(|((property, operator), value), span| VSFilter {
            property,
            operator,
            value,
            span: to_range(span),
        })
}

fn code_literal<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<Code>, ParserExtra<'tokens>> + Clone {
    select! { Token::Code(system, code) => (system, code) }.map_with_span(|(system, code), span| {
        Spanned {
            value: Code {
                system: if system.is_empty() {
                    None
                } else {
                    Some(system)
                },
                code,
                display: None,
            },
            span: to_range(span),
        }
    })
}

fn value_literal<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<Value>, ParserExtra<'tokens>> + Clone {
    let string_value = select! { Token::String(value) => value }
        .or(select! { Token::MultilineString(value) => value })
        .map(Value::String);

    let boolean = select! {
        Token::True => Value::Boolean(true),
        Token::False => Value::Boolean(false),
    };

    let number = select! { Token::Number(value) => value }
        .map(|text: String| text.parse::<f64>().unwrap_or_default())
        .map(Value::Number);

    let code = select! { Token::Code(system, code) => (system, code) }.map(|(system, code)| {
        Value::Code(Code {
            system: if system.is_empty() {
                None
            } else {
                Some(system)
            },
            code,
            display: None,
        })
    });

    let identifier = select! { Token::Ident(value) => Value::Identifier(value) };

    choice((string_value, boolean, number, code, identifier)).map_with_span(|value, span| Spanned {
        value,
        span: to_range(span),
    })
}

fn string_like<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<String>, ParserExtra<'tokens>> + Clone {
    choice((
        select! { Token::Ident(value) => value },
        select! { Token::String(value) => value },
        select! { Token::MultilineString(value) => value },
    ))
    .map_with_span(|value, span| Spanned {
        value,
        span: to_range(span),
    })
}

fn name<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<String>, ParserExtra<'tokens>> + Clone {
    string_like()
}

fn to_range(span: LexSpan) -> std::ops::Range<usize> {
    span.start()..span.end()
}

// ============================================================================
// Alias Parser
// ============================================================================

fn alias_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Alias, ParserExtra<'tokens>> + Clone {
    just(Token::Alias)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then_ignore(just(Token::Equal))
        .then(string_like())
        .map_with_span(|(name, value), span| Alias {
            name,
            value,
            span: to_range(span),
        })
}

// ============================================================================
// Profile Parser
// ============================================================================

fn profile_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Profile, ParserExtra<'tokens>> + Clone {
    just(Token::Profile)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(profile_metadata().repeated().collect::<Vec<_>>())
        .then(sd_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut profile = Profile {
                name,
                parent: None,
                id: None,
                title: None,
                description: None,
                rules,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    ProfileMetadata::Parent(parent) => profile.parent = Some(parent),
                    ProfileMetadata::Id(id) => profile.id = Some(id),
                    ProfileMetadata::Title(title) => profile.title = Some(title),
                    ProfileMetadata::Description(desc) => profile.description = Some(desc),
                }
            }

            profile
        })
}

#[derive(Debug, Clone)]
enum ProfileMetadata {
    Parent(Spanned<String>),
    Id(Spanned<String>),
    Title(Spanned<String>),
    Description(Spanned<String>),
}

fn profile_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ProfileMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Parent)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ProfileMetadata::Parent),
        just(Token::Id)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ProfileMetadata::Id),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ProfileMetadata::Title),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ProfileMetadata::Description),
    ))
}

fn sd_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, SDRule, ParserExtra<'tokens>> + Clone {
    choice((
        card_rule().map(SDRule::Card),
        flag_rule().map(SDRule::Flag),
        valueset_binding_rule().map(SDRule::ValueSet),
        fixed_value_rule().map(SDRule::FixedValue),
        contains_rule().map(SDRule::Contains),
        only_rule().map(SDRule::Only),
        obeys_rule().map(SDRule::Obeys),
        caret_value_rule().map(SDRule::CaretValue),
        insert_rule().map(SDRule::Insert),
        path_rule().map(SDRule::Path),
    ))
}

fn card_rule<'tokens>()
-> impl Parser<'tokens, Stream<'tokens, Token, LexSpan>, CardRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path())
        .then(cardinality())
        .then(flags().or_not())
        .map_with(|((path, cardinality), flags), ext| CardRule {
            path,
            cardinality,
            flags: flags.unwrap_or_default(),
            span: to_range(ext.span()),
        })
}

fn flag_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, FlagRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path().separated_by(just(Token::Comma)).at_least(1).collect::<Vec<_>>())
        .then(flags())
        .map_with_span(|(paths, flags), span| FlagRule {
            paths,
            flags,
            span: to_range(span),
        })
}

fn valueset_binding_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ValueSetRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path())
        .then_ignore(just(Token::From))
        .then(string_like())
        .then(
            just(Token::LParen)
                .ignore_then(binding_strength())
                .then_ignore(just(Token::RParen))
                .or_not(),
        )
        .map_with_span(|((path, value_set), strength), span| ValueSetRule {
            path,
            value_set,
            strength,
            span: to_range(span),
        })
}

fn fixed_value_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, FixedValueRule, ParserExtra<'tokens>> + Clone {
    let exactly = just(Token::Exactly).to(true).or_not();

    just(Token::Star)
        .ignore_then(path())
        .then_ignore(just(Token::Equal))
        .then(exactly)
        .then(value_literal())
        .map_with_span(|((path, exactly), value), span| FixedValueRule {
            path,
            value,
            exactly: exactly.unwrap_or(false),
            span: to_range(span),
        })
}

fn contains_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ContainsRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path())
        .then_ignore(just(Token::Contains))
        .then(
            contains_item()
                .separated_by(just(Token::And))
                .at_least(1)
                .collect::<Vec<_>>(),
        )
        .map_with_span(|(path, items), span| ContainsRule {
            path,
            items,
            span: to_range(span),
        })
}

fn contains_item<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ContainsItem, ParserExtra<'tokens>> + Clone {
    string_like()
        .then(
            just(Token::Named)
                .ignore_then(string_like())
                .or_not(),
        )
        .then(cardinality().or_not())
        .then(flags().or_not())
        .map_with_span(|(((name, named_as), cardinality), flags), span| ContainsItem {
            name,
            named_as,
            cardinality,
            flags: flags.unwrap_or_default(),
            span: to_range(span),
        })
}

fn only_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, OnlyRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path())
        .then_ignore(just(Token::Only))
        .then(
            string_like()
                .separated_by(just(Token::Or))
                .at_least(1)
                .collect::<Vec<_>>(),
        )
        .map_with_span(|(path, types), span| OnlyRule {
            path,
            types,
            span: to_range(span),
        })
}

fn obeys_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ObeysRule, ParserExtra<'tokens>> + Clone {
    let path_then_obeys = path().map(Some).then_ignore(just(Token::Obeys));
    let just_obeys = just(Token::Obeys).to(None::<Spanned<String>>);

    just(Token::Star)
        .ignore_then(path_then_obeys.or(just_obeys))
        .then(
            string_like()
                .separated_by(just(Token::And))
                .at_least(1)
                .collect::<Vec<_>>(),
        )
        .map_with_span(|(path, invariants), span| ObeysRule {
            path,
            invariants,
            span: to_range(span),
        })
}

fn path_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, PathRule, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(path())
        .map_with_span(|path, span| PathRule {
            path,
            span: to_range(span),
        })
}

// ============================================================================
// Extension Parser
// ============================================================================

fn extension_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Extension, ParserExtra<'tokens>> + Clone {
    just(Token::Extension)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(extension_metadata().repeated().collect::<Vec<_>>())
        .then(sd_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut extension = Extension {
                name,
                parent: None,
                id: None,
                title: None,
                description: None,
                contexts: Vec::new(),
                rules,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    ExtensionMetadata::Parent(parent) => extension.parent = Some(parent),
                    ExtensionMetadata::Id(id) => extension.id = Some(id),
                    ExtensionMetadata::Title(title) => extension.title = Some(title),
                    ExtensionMetadata::Description(desc) => extension.description = Some(desc),
                    ExtensionMetadata::Context(ctx) => extension.contexts.push(ctx),
                }
            }

            extension
        })
}

#[derive(Debug, Clone)]
enum ExtensionMetadata {
    Parent(Spanned<String>),
    Id(Spanned<String>),
    Title(Spanned<String>),
    Description(Spanned<String>),
    Context(Spanned<String>),
}

fn extension_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, ExtensionMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Parent)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ExtensionMetadata::Parent),
        just(Token::Id)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ExtensionMetadata::Id),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ExtensionMetadata::Title),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ExtensionMetadata::Description),
        just(Token::Context)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(ExtensionMetadata::Context),
    ))
}

// ============================================================================
// Instance Parser
// ============================================================================

fn instance_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Instance, ParserExtra<'tokens>> + Clone {
    just(Token::Instance)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(instance_metadata().repeated().collect::<Vec<_>>())
        .then(instance_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut instance = Instance {
                name,
                instance_of: None,
                title: None,
                description: None,
                usage: None,
                rules,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    InstanceMetadata::InstanceOf(instance_of) => instance.instance_of = Some(instance_of),
                    InstanceMetadata::Title(title) => instance.title = Some(title),
                    InstanceMetadata::Description(desc) => instance.description = Some(desc),
                    InstanceMetadata::Usage(usage) => instance.usage = Some(usage),
                }
            }

            instance
        })
}

#[derive(Debug, Clone)]
enum InstanceMetadata {
    InstanceOf(Spanned<String>),
    Title(Spanned<String>),
    Description(Spanned<String>),
    Usage(Spanned<String>),
}

fn instance_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, InstanceMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::InstanceOf)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InstanceMetadata::InstanceOf),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InstanceMetadata::Title),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InstanceMetadata::Description),
        just(Token::Usage)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InstanceMetadata::Usage),
    ))
}

fn instance_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, InstanceRule, ParserExtra<'tokens>> + Clone {
    choice((
        fixed_value_rule().map(InstanceRule::FixedValue),
        insert_rule().map(InstanceRule::Insert),
        path_rule().map(InstanceRule::Path),
    ))
}

// ============================================================================
// CodeSystem Parser
// ============================================================================

fn code_system_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, CodeSystem, ParserExtra<'tokens>> + Clone {
    just(Token::CodeSystem)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(metadata().repeated().collect::<Vec<_>>())
        .then(cs_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut code_system = CodeSystem {
                name,
                id: None,
                title: None,
                description: None,
                concepts: Vec::new(),
                rules: Vec::new(),
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    Metadata::Id(id) => code_system.id = Some(id),
                    Metadata::Title(title) => code_system.title = Some(title),
                    Metadata::Description(desc) => code_system.description = Some(desc),
                }
            }

            code_system.rules = rules;
            code_system
        })
}

fn cs_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, CSRule, ParserExtra<'tokens>> + Clone {
    choice((
        concept_rule().map(CSRule::Concept),
        code_caret_value_rule().map(CSRule::CodeCaretValue),
        code_insert_rule().map(CSRule::CodeInsert),
    ))
}

fn concept_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Concept, ParserExtra<'tokens>> + Clone {
    just(Token::Star)
        .ignore_then(code_literal().repeated().at_least(1).collect::<Vec<_>>())
        .then(
            string_like()
                .map(Some)
                .or_not()
                .map(|opt| opt.flatten()),
        )
        .map_with_span(|(codes, display), span| Concept {
            codes,
            display,
            definition: None,
            span: to_range(span),
        })
}

// ============================================================================
// Invariant Parser
// ============================================================================

fn invariant_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Invariant, ParserExtra<'tokens>> + Clone {
    just(Token::Invariant)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(invariant_metadata().repeated().collect::<Vec<_>>())
        .map_with_span(|(name, metadata), span| {
            let mut invariant = Invariant {
                name,
                description: None,
                expression: None,
                xpath: None,
                severity: None,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    InvariantMetadata::Description(desc) => invariant.description = Some(desc),
                    InvariantMetadata::Expression(expr) => invariant.expression = Some(expr),
                    InvariantMetadata::XPath(xpath) => invariant.xpath = Some(xpath),
                    InvariantMetadata::Severity(severity) => invariant.severity = Some(severity),
                }
            }

            invariant
        })
}

#[derive(Debug, Clone)]
enum InvariantMetadata {
    Description(Spanned<String>),
    Expression(Spanned<String>),
    XPath(Spanned<String>),
    Severity(Spanned<String>),
}

fn invariant_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, InvariantMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InvariantMetadata::Description),
        just(Token::Expression)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InvariantMetadata::Expression),
        just(Token::XPath)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InvariantMetadata::XPath),
        just(Token::Severity)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(InvariantMetadata::Severity),
    ))
}

// ============================================================================
// Mapping Parser
// ============================================================================

fn mapping_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Mapping, ParserExtra<'tokens>> + Clone {
    just(Token::Mapping)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(mapping_metadata().repeated().collect::<Vec<_>>())
        .map_with_span(|(name, metadata), span| {
            let mut mapping = Mapping {
                name,
                id: None,
                source: None,
                target: None,
                description: None,
                title: None,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    MappingMetadata::Id(id) => mapping.id = Some(id),
                    MappingMetadata::Source(source) => mapping.source = Some(source),
                    MappingMetadata::Target(target) => mapping.target = Some(target),
                    MappingMetadata::Description(desc) => mapping.description = Some(desc),
                    MappingMetadata::Title(title) => mapping.title = Some(title),
                }
            }

            mapping
        })
}

#[derive(Debug, Clone)]
enum MappingMetadata {
    Id(Spanned<String>),
    Source(Spanned<String>),
    Target(Spanned<String>),
    Description(Spanned<String>),
    Title(Spanned<String>),
}

fn mapping_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, MappingMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Id)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(MappingMetadata::Id),
        just(Token::Source)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(MappingMetadata::Source),
        just(Token::Target)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(MappingMetadata::Target),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(MappingMetadata::Description),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(MappingMetadata::Title),
    ))
}

// ============================================================================
// Logical Parser
// ============================================================================

fn logical_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Logical, ParserExtra<'tokens>> + Clone {
    just(Token::Logical)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(logical_metadata().repeated().collect::<Vec<_>>())
        .then(lr_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut logical = Logical {
                name,
                parent: None,
                id: None,
                title: None,
                description: None,
                characteristics: Vec::new(),
                rules,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    LogicalMetadata::Parent(parent) => logical.parent = Some(parent),
                    LogicalMetadata::Id(id) => logical.id = Some(id),
                    LogicalMetadata::Title(title) => logical.title = Some(title),
                    LogicalMetadata::Description(desc) => logical.description = Some(desc),
                    LogicalMetadata::Characteristics(chars) => logical.characteristics.push(chars),
                }
            }

            logical
        })
}

#[derive(Debug, Clone)]
enum LogicalMetadata {
    Parent(Spanned<String>),
    Id(Spanned<String>),
    Title(Spanned<String>),
    Description(Spanned<String>),
    Characteristics(Spanned<String>),
}

fn logical_metadata<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, LogicalMetadata, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Parent)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(LogicalMetadata::Parent),
        just(Token::Id)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(LogicalMetadata::Id),
        just(Token::Title)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(LogicalMetadata::Title),
        just(Token::Description)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(LogicalMetadata::Description),
        just(Token::Characteristics)
            .ignore_then(just(Token::Colon))
            .ignore_then(string_like())
            .map(LogicalMetadata::Characteristics),
    ))
}

// ============================================================================
// Resource Parser
// ============================================================================

fn resource_parser<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Resource, ParserExtra<'tokens>> + Clone {
    just(Token::Resource)
        .ignore_then(just(Token::Colon))
        .ignore_then(name())
        .then(profile_metadata().repeated().collect::<Vec<_>>())
        .then(lr_rule().repeated().collect::<Vec<_>>())
        .map_with_span(|((name, metadata), rules), span| {
            let mut resource = Resource {
                name,
                parent: None,
                id: None,
                title: None,
                description: None,
                rules,
                span: to_range(span),
            };

            for meta in metadata {
                match meta {
                    ProfileMetadata::Parent(parent) => resource.parent = Some(parent),
                    ProfileMetadata::Id(id) => resource.id = Some(id),
                    ProfileMetadata::Title(title) => resource.title = Some(title),
                    ProfileMetadata::Description(desc) => resource.description = Some(desc),
                }
            }

            resource
        })
}

fn lr_rule<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, LRRule, ParserExtra<'tokens>> + Clone {
    choice((
        sd_rule().map(LRRule::SD),
        // add_element_rule().map(LRRule::AddElement), // TODO: Implement AddElement rule
    ))
}

// ============================================================================
// Helper Parsers
// ============================================================================

fn path<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<String>, ParserExtra<'tokens>> + Clone {
    string_like()
}

fn cardinality<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<Cardinality>, ParserExtra<'tokens>> + Clone {
    let number = select! { Token::Number(n) => n };
    let star = just(Token::Star).to("*".to_string());

    number
        .or(star.clone())
        .then_ignore(just(Token::Colon).then(just(Token::Colon)))
        .then(number.or(star))
        .map_with_span(|(min_str, max_str), span| {
            let min = if min_str == "*" {
                None
            } else {
                min_str.parse::<u32>().ok()
            };

            let max = if max_str == "*" {
                CardinalityMax::Star
            } else {
                CardinalityMax::Number(max_str.parse::<u32>().unwrap_or(0))
            };

            Spanned {
                value: Cardinality { min, max },
                span: to_range(span),
            }
        })
}

fn flags<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Vec<Spanned<Flag>>, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::MS).to(Flag::MS),
        just(Token::SU).to(Flag::SU),
        just(Token::TU).to(Flag::TU),
        just(Token::N).to(Flag::N),
        just(Token::D).to(Flag::D),
        just(Token::Mod).to(Flag::Modifier),
    ))
    .map_with_span(|flag, span| Spanned {
        value: flag,
        span: to_range(span),
    })
    .repeated()
    .at_least(1)
    .collect::<Vec<_>>()
}

fn binding_strength<'tokens>()
-> impl Parser<'tokens, ParserInput<'tokens>, Spanned<BindingStrength>, ParserExtra<'tokens>> + Clone {
    choice((
        just(Token::Required).to(BindingStrength::Required),
        just(Token::Extensible).to(BindingStrength::Extensible),
        just(Token::Preferred).to(BindingStrength::Preferred),
        just(Token::Example).to(BindingStrength::Example),
    ))
    .map_with_span(|strength, span| Spanned {
        value: strength,
        span: to_range(span),
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::lexer::lex;
    use chumsky::span::Span as _;

    #[test]
    fn parse_valueset_document() {
        let input = r#"
ValueSet: TestVS
Id: test-vs
Title: "Test ValueSet"
Description: "Example"
* include codes from system http://loinc.org where concept is-a #8310-5
* exclude http://loinc.org#94563-4
* ^compose.include[0].display = "Blood Pressure"
* #8310-5 insert CommonCodes
"#;

        let (tokens, lex_errors) = lex(input);
        assert!(lex_errors.is_empty(), "Lexer errors: {:?}", lex_errors);

        let eof = LexSpan::new(input.len(), input.len());
        let (document, parse_errors) = parse_tokens(&tokens, eof);
        assert!(parse_errors.is_empty(), "Parse errors: {:?}", parse_errors);

        let document = document.expect("expected parsed document");
        assert_eq!(document.value_sets.len(), 1);
        let vs = &document.value_sets[0];
        assert_eq!(vs.name.value, "TestVS");
        assert_eq!(vs.id.as_ref().map(|id| id.value.as_str()), Some("test-vs"));
        assert_eq!(vs.components.len(), 2);
        assert_eq!(vs.rules.len(), 2);
    }
}
